# Voyage AI ‚Äî √âvaluation pour LobsterOps
**Date:** 2026-02-17  
**Trigger:** @YannDecoopman (IZHC) setup de m√©moire persistante multi-agents  
**D√©cision requise:** L2 (modification openclaw.json pour `memorySearch.provider = "voyage"`)

---

## Qu'est-ce que Voyage AI ?

API d'embeddings s√©mantiques recommand√©e par Anthropic. Convertit du texte en vecteurs pour la recherche s√©mantique ‚Äî synonymes, contexte, pas juste du keyword matching.

**Cas d'usage :** indexer un vault de fichiers .md pour que les agents retrouvent des informations par sens, pas par mot-cl√© exact. Ex : chercher "co√ªt d'utilisation Claude" trouve aussi les fichiers mentionnant "token budget", "prix API", "360√ó".

---

## Pricing

| Mod√®le | Prix/million tokens | Free tier |
|--------|-------------------|-----------|
| voyage-4-large | $0.12 | 200M tokens gratuits |
| voyage-4 | $0.06 | 200M tokens gratuits |
| **voyage-4-lite** | **$0.02** | **200M tokens gratuits** |
| voyage-context-3 | $0.18 | 200M tokens gratuits |
| rerank-2.5 | $0.05 | 200M tokens gratuits |

**Pour notre volume (~150KB, ~50 fichiers) :**
- 150KB de texte ‚âà ~37 500 tokens
- Free tier = 200 000 000 tokens
- Ratio : **37 500 / 200 000 000 = 0.019%** du free tier
- Co√ªt apr√®s free tier : ~$0.00075 par indexation compl√®te du vault
- **Verdict pricing : quasi gratuit, le free tier suffit pour des ann√©es d'usage normal**

---

## Int√©gration OpenClaw

**Support natif confirm√©** (docs.openclaw.ai/reference/api-usage-costs) :

```
memorySearch.provider = "voyage"
```

OpenClaw supporte nativement :
- `memorySearch.provider = "voyage"` ‚Üê Voyage AI
- `memorySearch.provider = "openai"` ‚Üê OpenAI
- `memorySearch.provider = "gemini"` ‚Üê Gemini
- `memorySearch.provider = "local"` ‚Üê local, z√©ro API

Int√©gration = modification `openclaw.json` ‚Üí **L2 approval requis**.

---

## Contraintes Data Privacy

### Ce qui est envoy√© √† Voyage AI
- Le **texte brut** de chaque fichier est envoy√© pour g√©n√©rer les embeddings
- Voyage AI cr√©e les vecteurs et les retourne ‚Äî le texte n'est **pas stock√©** dans un index permanent (contrairement √† Supermemory)
- Files API : fichiers retenus 30 jours (usage batch uniquement, pas pertinent ici)

### ‚ö†Ô∏è Avertissement @YannDecoopman
*"Ne stockez PAS vos cl√©s et acc√®s dans le vault car √ßa se retrouve index√© par Voyage AI."*

### Ce que √ßa implique pour notre vault
| Fichier | Sensibilit√© | Verdict |
|---------|------------|---------|
| `research/lobsterops/*.md` | üü¢ Faible | OK √† envoyer |
| `memory/YYYY-MM-DD.md` | üü° Moyen | Contexte op√©rationnel |
| `MEMORY.md` | üü° Moyen | Profil Blaise, pr√©f√©rences |
| `SOUL.md`, `AGENTS.md` | üü¢ Faible | Architecture, r√®gles |
| `vault/lessons/*.md` | üü° Moyen | Incidents, le√ßons |
| **Credentials** | üî¥ JAMAIS | D√©j√† dans env vars, jamais dans les fichiers |

**Notre situation actuelle :** Credentials d√©j√† en env vars (‚úÖ conforme). Le reste est du contexte op√©rationnel ‚Äî pas d'informations hautement sensibles dans les fichiers actuels.

**Diff√©rence vs Supermemory :** Voyage AI cr√©e des vecteurs depuis le texte, mais ne stocke pas les conversations/contexte dans une base de donn√©es tierce. C'est une embedding API, pas un service de m√©moire persistante cloud.

---

## Alternatives Self-Hosted

| Option | Setup | Qualit√© | Co√ªt |
|--------|-------|---------|------|
| `memorySearch.provider = "local"` (OpenClaw natif) | Z√©ro | Inf√©rieure | $0 |
| Ollama + nomic-embed-text | Moyen | Bonne | $0 (CPU) |
| sentence-transformers (Python) | Complexe | Tr√®s bonne | $0 (CPU) |
| **Voyage AI** | Faible (config) | Excellente | ~$0 (free tier) |

**Notre VPS** : 1-2 vCPUs ‚Üí mod√®les locaux = lent. Voyage AI = 200ms par batch ‚Üí clairement sup√©rieur pour notre setup.

---

## Setup de Yann Decoopman (Pattern IZHC)

1. **Obsidian** (.md li√©s logiquement) ‚Üê on fait d√©j√†
2. **Bilan quotidien standardis√©** par agent ‚Üê on fait d√©j√† (memory/YYYY-MM-DD.md)
3. **Voyage AI** pour indexation s√©mantique du vault entier
4. **Propagation automatique** : quand un agent indexe, la connaissance est accessible √† tous
5. **PDF ‚Üí .md** avant indexation (pour les documents importants)

**Diff√©renciateur cl√©** : *"Quand un agent cherche un truc, il indexe la m√©moire pour tous les autres ‚Äî la connaissance se propage entre agents automatiquement."*

---

## Comparaison vs Notre Setup Actuel

| Aspect | Actuel (ClawVault + memory-core) | Avec Voyage AI |
|--------|----------------------------------|----------------|
| Type de search | Tools manuels + FTS5 (keyword) | S√©mantique (synonymes, contexte) |
| D√©clenchement | Manuel (tool call) | Configurable (hooks ou manual) |
| Qualit√© retrieval | Bonne (107 nodes graph) | Excellente (+31.7pp benchmark) |
| Multi-agent | Via Canal Direct | Automatique (shared vault index√©) |
| Co√ªt | $0 | ~$0 (free tier) |
| Privacy | Local total | Texte envoy√© pour embedding |
| Setup | D√©j√† fait | config change L2 |

---

## Recommandation

**Score risque/b√©n√©fice : FAVORABLE** ‚Äî contrairement √† Supermemory (cloud m√©moire persistante), Voyage AI est une API d'embeddings stateless. Le texte est envoy√© pour cr√©er des vecteurs, pas stock√© dans une base de donn√©es tierce interrogeable.

**‚ö†Ô∏è Condition pr√©alable :** Audit rapide du vault pour s'assurer qu'aucune credential n'est dans les fichiers .md (d√©j√† v√©rifi√© : credentials en env vars ‚úÖ).

**Proposition L2 :**
1. Ajouter `VOYAGE_API_KEY` en env var (signup gratuit sur voyageai.com)
2. Modifier `openclaw.json` : `memorySearch.provider = "voyage"`, model `voyage-4-lite`
3. Tester sur Ralph uniquement d'abord (pas The Constituent)
4. √âvaluer qualit√© des r√©sultats memory_search vs actuel

**Mod√®le recommand√© :** `voyage-4-lite` ($0.02/million, free tier 200M) ‚Äî suffisant pour notre volume, le meilleur rapport qualit√©/prix pour le use case.

---

## Action Required

**L2 ‚Äî Blaise approval needed** avant tout changement.  
Si approuv√©, setup estim√© : 15 min (signup + config change + test).
